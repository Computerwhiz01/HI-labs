Getting started guide for Hadoop Developer Labs
-----------------------------------------------

lab location : https://github.com/elephantscale/HI-labs

== STEP 1) login to the cluster
Login in to the cluster assigned to you using SSH.  Instructor will provide details.
    $  ssh <user name>@<hostname>
    e.g $  ssh ec2-user@ec2.........

    You will be placed in home dir : /home/<login user>
    e.g.    /home/ubuntu    or /home/ec2-user


== STEP 2) : Make a personal workspace in linux

after you login
        $  cd    # get to home dir
        $  mkdir   <your name>
e.g.    $  mkdir   sujee
        $ cd   <your name>     #   <-- this is your personal space


== STEP 3) : get code from github

Get the code from github into your personal workspace
        $   cd <your personal workspace dir you just created>
e.g.    $   cd sujee

There are two ways you can do this:

1) using git
    $   git clone --depth 1  https://github.com/elephantscale/HI-labs.git

2) or download the zip file
    2a) click 'download as zip' button on the github url above

    2b) using command line
        $  wget 'https://github.com/elephantscale/HI-labs/archive/master.zip'
        $  unzip master.zip

This will create a dir called 'HI-labs'.  This will be the project root

== STEP 4) : Cluster inspection, NameNode, JobTracer

If you are using Cloudera Manager (CM)

1) CM interface is found at <manager-url>:7180
2) NameNode interface, with the HDFS, is found at <namenode-url>:50070. To find the <namenode-url>, to to HDFS in CM
3) JobTracker interface is found at <jobtracker-url>:50030. To find the <namenode-url>, to to mapreduce in CM

If you want to see the NameNode and JobTracker on the command line, in ssh, do this

1) NameNode: w3m http://<namenode-url>:50070. You can login to the namenode and use the internal ip for that.
1) JobTracker: w3m http://<jobtracker-url>:50030. You can login to the jobtracker and use the internal ip for that.

=== for Instructor only  ====
Create a HDFS home dir for <login user>  (hdfs:///user/<login_name>)
    $  sudo -s  #  if needed
    $  sudo -u hdfs  hdfs  dfs -mkdir /user/<login_name>

e.g $  sudo -u hdfs  hdfs  dfs -mkdir /user/ec2-user

set the permissions
    $  sudo -u hdfs  hdfs dfs  -chown <login_name> /user/<login_name>
e.g $  sudo -u hdfs  hdfs dfs  -chown ec2-user /user/ec2-user

verify permissions
    $   hdfs  dfs -ls /user/
make sure a directory named '/user/<login_user>' exists and is owned by <login_user>
=== end Instructor ====

